num_examples, with test_ratio = 0.25
dset1: train=2985 test = 1047
dest2: train=2996 test = 1044

255*230
1600*1200
204*204
1332*2020
2640*1760
crop思路：先把最短边resize到160像素，再crop出160*24/32=120的图像来

### 0423
ecm机器上，K80算两个gpu，设备列表如下：
/device:CPU:0
/device:GPU:0
/device:GPU:1

目前跑的代码把两块的显存都占满了，但是算力没满

笔记本设备列表：
/device:CPU:0
/device:GPU:0

计算一下每个batch占用的空间？(每个像素是32位浮点数）：128*120*120*3*32/8 = 22.5MB  那为什么能占据5G的显存？

运行到2200steps时发散，表示2200个batch，
每个epoch包含3000/128=24个batch， 所以有91个epoch。  所以干脆70个epoch就进行lr衰减吧, factor 设置为0.2
res：最终的lr下降到了一个比较小的数值，最终的loss始终在11.3左右徘徊，但这个其实也包含了weight正则项带来的loss，需要考虑新的训练方法。
res : train accuracy 0.946 or 0.954, test accuracy 0.314

0424
对变量做滑动平均有利于提升效果

0425
连夜搭建的复杂模型val acc也只是到了0.38，train acc 为0.6，可能跟early stop设置的阈值太小训练时间不够有关系？